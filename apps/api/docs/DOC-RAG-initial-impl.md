Implementaci√≥n de Drizzle, PostgreSQL Local y RAG B√°sico

## Resumen General
Implementaci√≥n inicial de RAG (Retrieval-Augmented Generation) con PostgreSQL local y Drizzle ORM, introduciendo capacidades de b√∫squeda sem√°ntica y almacenamiento de embeddings para el asistente financiero.

## Cambios Principales

### 1. Configuraci√≥n de Base de Datos PostgreSQL (Solo para trabajar en local)
- **Archivo**: `apps/api/docker-compose.yml`
- **Implementaci√≥n**: PostgreSQL con extensi√≥n pgvector
- **Configuraci√≥n**: Usuario `rag`, base de datos `finapsis-rag`
- **Puerto**: 5432

### 2. Integraci√≥n de Drizzle ORM
- **Configuraci√≥n**: `apps/api/drizzle.config.ts`
- **Scripts**: Migraci√≥n, generaci√≥n de esquemas, studio, push/pull
- **Esquemas**: Ubicados en `src/providers/supabase/schema`

### 3. Esquemas de Base de Datos

#### Tabla `resources`
```sql
CREATE TABLE resources (
  id varchar(191) PRIMARY KEY,
  content text NOT NULL,
  created_at timestamp DEFAULT now(),
  updated_at timestamp DEFAULT now()
);
```

#### Tabla `embeddings`
```typescript
export const embeddings = pgTable(
  'embeddings',
  {
    id: varchar('id', {length: 191}).primaryKey(),
    resourceId: varchar('resource_id').references(() => resources.id),
    content: text('content').notNull(),
    embedding: vector('embedding', {dimensions: 1536}).notNull(),
  },
  // √çndice HNSW para b√∫squeda de vectores
  table => ({
    embeddingIndex: index('embeddingIndex')
      .using('hnsw', table.embedding.op('vector_cosine_ops'))
  })
);
```

### 4. Servicios de Embeddings

#### Generaci√≥n de Embeddings
- **Modelo**: OpenAI `text-embedding-ada-002`
- **Chunking**: Inteligente por oraciones y p√°rrafos (max 300 caracteres)
- **Batch Processing**: M√∫ltiples chunks simult√°neos

#### B√∫squeda Sem√°ntica
```typescript
export const findRelevantContent = async (userQuery: string) => {
  const userQueryEmbedded = await generateEmbedding(userQuery);
  const similarity = sql<number>`1 - (${cosineDistance(embeddings.embedding, userQueryEmbedded)})`;
  
  return supabase.select({content: embeddings.content, similarity})
    .from(embeddings)
    .where(gt(similarity, 0.5))
    .orderBy(desc(similarity))
    .limit(4);
}
```

### 5. Herramientas del Asistente

#### ADD_KNOWLEDGE Tool
- **Prop√≥sito**: Agregar informaci√≥n a la base de conocimientos
- **Uso**: Autom√°tico cuando el usuario proporciona datos personales
- **Funcionalidad**: Genera embeddings y los almacena

#### FIND_RELEVANT_KNOWLEDGE Tool
- **Prop√≥sito**: Buscar informaci√≥n relevante antes de responder
- **Obligatorio**: Debe usarse para TODA pregunta del usuario
- **Threshold**: Similaridad m√≠nima de 0.5

### 6. Personalidad del Asistente Financiero
```typescript
const CONTENT_ONLY_RAG = `Eres un asistente financiero especializado en el mercado chileno üá®üá±
PERSONALIDAD Y TONO:
- S√© divertido y usa emojis apropiados üòä
- EXCEPCI√ìN: Si hablan de deudas, mant√©n un tono serio
- No seas infantil, equilibrio profesional y amigable

MONEDA Y C√ÅLCULOS:
- Asume pesos chilenos (CLP) por defecto
- S√© MUY EXACTO con c√°lculos matem√°ticos

FUNCIONAMIENTO:
- OBLIGATORIO: PRIMERO usa FIND_RELEVANT_KNOWLEDGE
- NUNCA respondas sin buscar en la base de conocimientos
- Auto-guarda informaci√≥n personal con ADD_KNOWLEDGE
```

### 7. Configuraci√≥n de Entorno
- **OpenAI API Key**: Para embeddings
- **DATABASE_URL**: PostgreSQL local
- **NODE_ENV**: Development con limpieza opcional de DB

### 8. Scripts de Base de Datos
```json
{
  "db:generate": "drizzle-kit generate",
  "db:migrate": "tsx src/providers/supabase/migrate.ts",
  "db:studio": "drizzle-kit studio",
  "dev:clear-db": "CLEAR_DB_ON_START=true bun run --hot src/index.ts"
}
```

## Arquitectura RAG Implementada

### Flujo de Almacenamiento
1. Usuario proporciona informaci√≥n ‚Üí ADD_KNOWLEDGE
2. Contenido se divide en chunks sem√°nticamente coherentes
3. Se generan embeddings con OpenAI ada-002
4. Se almacenan en PostgreSQL con √≠ndice HNSW

### Flujo de Recuperaci√≥n
1. Usuario hace pregunta ‚Üí FIND_RELEVANT_KNOWLEDGE (obligatorio)
2. Se genera embedding de la pregunta
3. B√∫squeda por similaridad coseno (threshold 0.5)
4. Se retornan los 4 resultados m√°s relevantes
5. El asistente responde basado en la informaci√≥n encontrada

### Chunking Inteligente
- Divide por oraciones con l√≠mite de 300 caracteres
- Preserva contexto sem√°ntico
- Maneja casos edge (textos cortos, una oraci√≥n)

### √çndice Vectorial Optimizado
- HNSW (Hierarchical Navigable Small World)
- Operador `vector_cosine_ops` para eficiencia
- B√∫squeda aproximada de vecinos m√°s cercanos

### Limpieza de Base de Datos
- Funci√≥n `clearAllData()` para desarrollo
- Respeta constrains de foreign keys
- Activable con variable de entorno

## Impacto en la Aplicaci√≥n

### Capacidades Nuevas
1. **Memoria Persistente**: El asistente recuerda informaci√≥n del usuario
2. **B√∫squeda Sem√°ntica**: Encuentra informaci√≥n relevante contextualmente
4. **Personalizaci√≥n**: Adapta respuestas basado en datos del usuario

## Consideraciones de Rendimiento
- Embeddings se generan de forma as√≠ncrona
- √çndice HNSW optimiza b√∫squedas vectoriales
- Limit de 4 resultados por consulta para eficiencia
- Threshold de similaridad evita resultados irrelevantes
